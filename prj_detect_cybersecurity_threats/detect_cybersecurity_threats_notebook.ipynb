{"cells":[{"cell_type":"markdown","id":"51be1f3d-e425-4d6d-9c05-fb6d98664c68","metadata":{},"source":["**INTRODUCTION**\n","Cyber threats are a growing concern for organizations worldwide. These threats take many forms, including malware, phishing, and denial-of-service (DOS) attacks, compromising sensitive information and disrupting operations. The increasing sophistication and frequency of these attacks make it imperative for organizations to adopt advanced security measures. Traditional threat detection methods often fall short due to their inability to adapt to new and evolving threats. This is where deep learning models come into play.\n","\n","Deep learning models can analyze vast amounts of data and identify patterns that may not be immediately obvious to human analysts. By leveraging these models, organizations can proactively detect and mitigate cyber threats, safeguarding their sensitive information and ensuring operational continuity.\n","\n","As a cybersecurity analyst, you identify and mitigate these threats. In this project, you will design and implement a deep learning model to detect cyber threats. The BETH dataset simulates real-world logs, providing a rich source of information for training and testing your model. The data has already undergone preprocessing, and we have a target label, `sus_label`, indicating whether an event is malicious (1) or benign (0).\n","\n","By successfully developing this model, you will contribute to enhancing cybersecurity measures and protecting organizations from potentially devastating cyber attacks."]},{"cell_type":"markdown","id":"8811256f-f887-4867-903e-837238fbb648","metadata":{},"source":["\n","### The Data\n","\n","| Column     | Description              |\n","|------------|--------------------------|\n","|`processId`|The unique identifier for the process that generated the event - int64 |\n","|`threadId`|ID for the thread spawning the log - int64|\n","|`parentProcessId`|Label for the process spawning this log - int64|\n","|`userId`|ID of user spawning the log|Numerical - int64|\n","|`mountNamespace`|Mounting restrictions the process log works within - int64|\n","|`argsNum`|Number of arguments passed to the event - int64|\n","|`returnValue`|Value returned from the event log (usually 0) - int64|\n","|`sus_label`|Binary label as suspicous event (1 is suspicious, 0 is not) - int64|\n","\n","More information on the dataset: [BETH dataset](accreditation.md)"]},{"cell_type":"markdown","metadata":{},"source":["This is a binary classification challenge. I will solve it by using neural networks with BCELoss loss function and evaluate by Accuracy metric by Torchmetric."]},{"cell_type":"markdown","metadata":{},"source":["**Import libraries and datasets**"]},{"cell_type":"code","execution_count":35,"id":"75892dec-9424-4c92-bf8e-2f9847b7d7cd","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1719411324096,"lastExecutedByKernel":"11eb9d61-5980-4f1b-80cf-2256613d2ed2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nfrom torchmetrics import Accuracy\n# from sklearn.metrics import accuracy_score  # uncomment to use sklearn"},"outputs":[],"source":["# Import required libraries\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as functional\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.optim as optim\n","from torchmetrics import Accuracy\n","# from sklearn.metrics import accuracy_score  # uncomment to use sklearn"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>processId</th>\n","      <th>threadId</th>\n","      <th>parentProcessId</th>\n","      <th>userId</th>\n","      <th>mountNamespace</th>\n","      <th>argsNum</th>\n","      <th>returnValue</th>\n","      <th>sus_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>381</td>\n","      <td>7337</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>4026532231</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>381</td>\n","      <td>7337</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>4026532231</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>381</td>\n","      <td>7337</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>4026532231</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7347</td>\n","      <td>7347</td>\n","      <td>7341</td>\n","      <td>0</td>\n","      <td>4026531840</td>\n","      <td>2</td>\n","      <td>-2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7347</td>\n","      <td>7347</td>\n","      <td>7341</td>\n","      <td>0</td>\n","      <td>4026531840</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   processId  threadId  parentProcessId  userId  mountNamespace  argsNum  \\\n","0        381      7337                1     100      4026532231        5   \n","1        381      7337                1     100      4026532231        1   \n","2        381      7337                1     100      4026532231        0   \n","3       7347      7347             7341       0      4026531840        2   \n","4       7347      7347             7341       0      4026531840        4   \n","\n","   returnValue  sus_label  \n","0            0          1  \n","1            0          1  \n","2            0          1  \n","3           -2          1  \n","4            0          1  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Load preprocessed data\n","train_df = pd.read_csv('data/labelled_train.csv')\n","test_df = pd.read_csv('data/labelled_test.csv')\n","val_df = pd.read_csv('data/labelled_validation.csv')\n","\n","# View the first 5 rows of training set\n","train_df.head()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(763144, 8)\n","(188967, 8)\n","(188967, 8)\n"]}],"source":["print(train_df.shape)\n","print(test_df.shape)\n","print(val_df.shape)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["sus_label\n","0    761875\n","1      1269\n","Name: count, dtype: int64\n"]}],"source":["#Check hơw many classes are in the dataset\n","print(train_df['sus_label'].value_counts())"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>processId</th>\n","      <th>threadId</th>\n","      <th>parentProcessId</th>\n","      <th>userId</th>\n","      <th>mountNamespace</th>\n","      <th>argsNum</th>\n","      <th>returnValue</th>\n","      <th>sus_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>763144.000000</td>\n","      <td>763144.000000</td>\n","      <td>763144.000000</td>\n","      <td>763144.000000</td>\n","      <td>7.631440e+05</td>\n","      <td>763144.000000</td>\n","      <td>763144.000000</td>\n","      <td>763144.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>6814.763308</td>\n","      <td>6820.265241</td>\n","      <td>1882.216609</td>\n","      <td>2.279034</td>\n","      <td>4.026532e+09</td>\n","      <td>2.672082</td>\n","      <td>17.520924</td>\n","      <td>0.001663</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1948.871187</td>\n","      <td>1937.068333</td>\n","      <td>2215.563094</td>\n","      <td>37.416576</td>\n","      <td>1.649030e+02</td>\n","      <td>1.340906</td>\n","      <td>318.596662</td>\n","      <td>0.040744</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.026532e+09</td>\n","      <td>0.000000</td>\n","      <td>-115.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>7313.000000</td>\n","      <td>7313.000000</td>\n","      <td>187.000000</td>\n","      <td>0.000000</td>\n","      <td>4.026532e+09</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>7365.000000</td>\n","      <td>7365.000000</td>\n","      <td>1385.000000</td>\n","      <td>0.000000</td>\n","      <td>4.026532e+09</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>7415.000000</td>\n","      <td>7415.000000</td>\n","      <td>1648.000000</td>\n","      <td>0.000000</td>\n","      <td>4.026532e+09</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>8619.000000</td>\n","      <td>8619.000000</td>\n","      <td>7672.000000</td>\n","      <td>1000.000000</td>\n","      <td>4.026532e+09</td>\n","      <td>5.000000</td>\n","      <td>8289.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           processId       threadId  parentProcessId         userId  \\\n","count  763144.000000  763144.000000    763144.000000  763144.000000   \n","mean     6814.763308    6820.265241      1882.216609       2.279034   \n","std      1948.871187    1937.068333      2215.563094      37.416576   \n","min         1.000000       1.000000         0.000000       0.000000   \n","25%      7313.000000    7313.000000       187.000000       0.000000   \n","50%      7365.000000    7365.000000      1385.000000       0.000000   \n","75%      7415.000000    7415.000000      1648.000000       0.000000   \n","max      8619.000000    8619.000000      7672.000000    1000.000000   \n","\n","       mountNamespace        argsNum    returnValue      sus_label  \n","count    7.631440e+05  763144.000000  763144.000000  763144.000000  \n","mean     4.026532e+09       2.672082      17.520924       0.001663  \n","std      1.649030e+02       1.340906     318.596662       0.040744  \n","min      4.026532e+09       0.000000    -115.000000       0.000000  \n","25%      4.026532e+09       1.000000       0.000000       0.000000  \n","50%      4.026532e+09       3.000000       0.000000       0.000000  \n","75%      4.026532e+09       4.000000       4.000000       0.000000  \n","max      4.026532e+09       5.000000    8289.000000       1.000000  "]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["train_df.describe()"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Scale data"]},{"cell_type":"markdown","metadata":{},"source":["1/ Separating Features and Labels: \n","- Drop the sus_label column from each DataFrame to separate features and assign the sus_label column to the labels\n","\n","2/ Scaling features: \n","- Initialize a StandardScaler() from sklearn.preprocessing to scale the features.\n","- Fit the scaler on the training data and transform the training data.\n","- Use the fitted scaler to transform the test and validation data.\n","\n","3/ Converting to PyTorch Tensors\n","- Convert the numpy arrays for features and labels to PyTorch tensors using torch.tensor().\n","- Ensure the features are converted to float32 type and the labels are reshaped to have a dimension of (-1, 1)."]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(763144,)\n"]}],"source":["#1. Separate features and labels\n","\n","# Define input features\n","features = train_df.drop(columns=['sus_label'])\n","\n","target = train_df['sus_label']\n","\n","print(target.shape)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["#2. Scaling features:\n","scaler = StandardScaler()\n","\n","# Fit the scaler to the data and transform it\n","scaled_features = scaler.fit_transform(features)"]},{"cell_type":"markdown","metadata":{},"source":["Why we need to reshape the value to (-1,1)?\n","- With the scaled features, we have 7 features with n sample => the size is [7]\n","- With the target, we need to transform to match after scaling features."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["input sample: tensor([-3.3013,  0.2668, -0.8491,  2.6117,  1.7840,  1.7361, -0.0550])\n","label sample: tensor([1.])\n"]}],"source":["#3. Converting to Pytorch Tensors - TensorDataset\n","\n","#Instantiate dataset class\n","dataset = TensorDataset(torch.tensor(scaled_features, dtype=torch.float32), torch.tensor(target.values, dtype=torch.float32).reshape(-1,1))\n","\n","#Access an individual sample\n","input_sample, label_sample = dataset[0]\n","print('input sample:', input_sample)   \n","print('label sample:', label_sample)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["#4. DataLoader\n","batch_size = 32\n","suffle = True\n","\n","# Create a DataLoader\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=suffle)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["#Test iterate over the dataloader\n","#for batch_inputs, batch_labels in dataloader:\n","#    print('batch_inputs:', batch_inputs.shape)\n","#    print('batch_labels:', batch_labels.shape)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["#5. Transform data and convert tensors with test data\n","test_features = test_df.drop(columns=['sus_label'])\n","\n","test_target = test_df['sus_label']\n","\n","# Fit the scaler to the data and transform it\n","scaled_test_features = scaler.fit_transform(test_features)\n","\n","#Instantiate dataset class\n","test_dataset = TensorDataset(torch.tensor(scaled_test_features, dtype=torch.float32), torch.tensor(test_target.values, dtype=torch.float32).reshape(-1,1))\n","\n","#DataLoader\n","batch_size = 32\n","suffle = True\n","\n","# Create a DataLoader\n","val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=suffle)\n"]},{"cell_type":"markdown","metadata":{},"source":["#2.  Define the Neural Network Model\n","1. Create a model\n","2. Choose a loss function\n","3. Define a dataset\n","4. Set an optimizer\n","5. Run a training loop:\n","- Calculate loss (forward pass)"]},{"cell_type":"markdown","metadata":{},"source":["Define a neural network model using PyTorch's nn.Sequential() to create a feed-forward neural network with specified layers and activations.\n","\n","1/ Creating the Model\n","- Use nn.Sequential() to define the model structure.\n","- Include three fully connected layers nn.Linear() with appropriate input and output dimensions.\n","- Add ReLU activation functions nn.ReLU() between the layers.\n","- Use a Sigmoid activation function nn.Sigmoid() at the output layer\n","\n","2/ Initializing Loss Function and Optimizer\n","- Use nn.CrossEntropyLoss().\n","- Initialize the optimizer using optim.SGD with a learning rate of 1e-3 and weight_decay 1e-4."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["#1. Create binary classification model\n","model = nn.Sequential(\n","    nn.Linear(7, 32),\n","    nn.ReLU(),\n","    nn.Linear(32, 16),\n","    nn.ReLU(),\n","    nn.Linear(16, 1),\n","    nn.Sigmoid()\n",")"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Linear(in_features=7, out_features=32, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=32, out_features=16, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=16, out_features=1, bias=True)\n","  (5): Sigmoid()\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["#2.4 Choose loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6729817390441895\n"]}],"source":["#Test with dummy data\n","dummy_X = torch.randn(4, 7)\n","\n","dummy_y = torch.tensor([[0.], [1.], [0.], [1.]])\n","\n","#Forward\n","dummy_output = model(dummy_X)\n","dummy_loss = criterion(dummy_output, dummy_y)\n","print(dummy_loss.item())"]},{"cell_type":"markdown","metadata":{},"source":["# Train and evaluate the model"]},{"cell_type":"markdown","metadata":{},"source":["Implement a training loop to train the neural network model using the training data. Update the model parameters based on the computed loss.\n","\n","1/ Setting Up the Training Loop\n","- Iterate through the specified number of epochs.\n","- Set the model to training mode using model.train().\n","- Clear the gradients using optimizer.zero_grad().\n","- Perform a forward pass to compute the model outputs.\n","- Compute the loss using the loss function.\n","- Perform a backward pass to compute the gradients.\n","- Update the model parameters using optimizer.step().\n","\n","2/ Evaluating the Model\n","- Evaluate the trained model on training, testing, and validation datasets. Calculate and print the accuracy for each dataset.\n","- Use torchmetrics.Accuracy() to calculate the accuracy for training, testing, and validation datasets."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Loss: 0.0638\n","Epoch 2/10, Loss: 0.0068\n","Epoch 3/10, Loss: 0.0057\n","Epoch 4/10, Loss: 0.0054\n","Epoch 5/10, Loss: 0.0052\n","Epoch 6/10, Loss: 0.0050\n","Epoch 7/10, Loss: 0.0049\n","Epoch 8/10, Loss: 0.0048\n","Epoch 9/10, Loss: 0.0047\n","Epoch 10/10, Loss: 0.0047\n"]}],"source":["#1. Train the model\n","num_epochs = 10  # Number of epochs\n","\n","for epoch in range(num_epochs):\n","    model.train()  # Training mode\n","    training_loss = 0.0\n","\n","    for feature, target in dataloader:\n","        # Zero gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        pred = model(feature)\n","\n","        # Compute loss\n","        loss = criterion(pred, target)\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","\n","        # Accumulate loss\n","        training_loss += loss.item()\n","\n","    # Average loss for the epoch\n","    epoch_loss = training_loss / len(dataloader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n","\n","        \n","        "]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=7, out_features=32, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=32, out_features=16, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=16, out_features=1, bias=True)\n","  (5): Sigmoid()\n",")"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["#2. Calculating validation loss\n","\n","validation_loss = 0.0\n","model.eval() #Put model to evaluation mode\n","\n","with torch.no_grad():\n","    for inputs, labels in val_loader:\n","        #Run the forward pass\n","        outputs = model(inputs)\n","        #Calculate the loss\n","        loss = criterion(outputs, labels)\n","        validation_loss += loss.item()\n","\n","epoch_loss = validation_loss / len(val_loader)\n","model.train()\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation Loss: 6.3214\n"]}],"source":["print(f\"Validation Loss: {epoch_loss:.4f}\")"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.0927\n"]}],"source":["#3. Evaluation Accuracy with TorchMetric\n","from torchmetrics import Accuracy\n","\n","acc = Accuracy(task='binary')\n","\n","model.eval()\n","\n","with torch.no_grad():\n","    for inputs, labels in val_loader:\n","        outputs = model(inputs)\n","        predictions = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n","        acc.update(predictions, labels.int())\n","\n","accuracy = acc.compute()\n","print(f\"Validation Accuracy: {accuracy:.4f}\")"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}
